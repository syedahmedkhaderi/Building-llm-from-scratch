{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### BYTE PAIR ENCODING"
      ],
      "metadata": {
        "id": "Uok6nfJlJmxT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We implemented a simple tokenization scheme in the previous sections for illustration\n",
        "purposes.\n",
        "\n",
        "This section covers a more sophisticated tokenization scheme based on a concept\n",
        "called byte pair encoding (BPE).\n",
        "\n",
        "The BPE tokenizer covered in this section was used to train\n",
        "LLMs such as GPT-2, GPT-3, and the original model used in ChatGPT."
      ],
      "metadata": {
        "id": "cvmKbNz_NhQ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since implementing BPE can be relatively complicated, we will use an existing Python\n",
        "open-source library called tiktoken (https://github.com/openai/tiktoken).\n",
        "\n",
        "This library implements\n",
        "the BPE algorithm very efficiently based on source code in Rust."
      ],
      "metadata": {
        "id": "QmeSay66N2g6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip3 install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "wTcAwvW7N7u8",
        "outputId": "907ed4f5-a960-40ef-9fe4-66e849459f81"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (0.12.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (2025.10.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qk7YNIqLJF-X",
        "outputId": "efdf684b-d301-478c-a078-d95aade98f47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tiktoken version: 0.12.0\n"
          ]
        }
      ],
      "source": [
        "import importlib\n",
        "import tiktoken\n",
        "\n",
        "print(\"tiktoken version:\", importlib.metadata.version(\"tiktoken\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can initialize the BPE tokenizer class"
      ],
      "metadata": {
        "id": "lx2uh8wUOEhv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ],
      "metadata": {
        "id": "YwwtqKUrOMpG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The usage of this tokenizer is similar to SimpleTokenizerV2 we implemented previously via\n",
        "an encode method:"
      ],
      "metadata": {
        "id": "ELw4NFVWOTvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = (\n",
        "    \"Hello, do you like tea? <|endoftext|> In the sunlit terraces\"\n",
        "     \"of someunknownPlace.\"\n",
        ")\n",
        "\n",
        "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "print(integers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5KT-kt8OVt5",
        "outputId": "9e07839b-236b-4c55-e1ef-8c873fd4c9be"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 1659, 617, 34680, 27271, 13]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can then convert the token IDs back into text using the decode method, similar to our\n",
        "SimpleTokenizerV2 earlier:"
      ],
      "metadata": {
        "id": "LRysd8TXOb--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "strings = tokenizer.decode(integers)\n",
        "\n",
        "print(strings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMVbRV83ObSt",
        "outputId": "2d306513-98a7-4386-d195-8e75116ff801"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, do you like tea? <|endoftext|> In the sunlit terracesof someunknownPlace.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can make two noteworthy observations based on the token IDs and decoded text\n",
        "above.\n",
        "\n",
        "First, the <|endoftext|> token is assigned a relatively large token ID, namely,\n",
        "50256.\n",
        "\n",
        "In fact, the BPE tokenizer, which was used to train models such as GPT-2, GPT-3,\n",
        "and the original model used in ChatGPT, has a total vocabulary size of 50,257, with\n",
        "<|endoftext|> being assigned the largest token ID.\n",
        "    "
      ],
      "metadata": {
        "id": "KuIno2IeOoDd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Second, the BPE tokenizer above encodes and decodes unknown words, such as\n",
        "\"someunknownPlace\" correctly.\n",
        "\n",
        "The BPE tokenizer can handle any unknown word. How does\n",
        "it achieve this without using <|unk|> tokens?\n",
        "    "
      ],
      "metadata": {
        "id": "cANJJUN1O0nd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The algorithm underlying BPE breaks down words that aren't in its predefined vocabulary\n",
        "into smaller subword units or even individual characters.\n",
        "\n",
        "This enables it to handle out-ofvocabulary words.\n",
        "\n",
        "So, thanks to the BPE algorithm, if the tokenizer encounters an\n",
        "unfamiliar word during tokenization, it can represent it as a sequence of subword tokens or\n",
        "characters"
      ],
      "metadata": {
        "id": "t6Jg7Q92O7v7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let us take another simple example to illustrate how the BPE tokenizer deals with unknown tokens**"
      ],
      "metadata": {
        "id": "lwFQHkSHPH9z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "integers = tokenizer.encode(\"Akwirw ier\")\n",
        "print(integers)\n",
        "\n",
        "strings = tokenizer.decode(integers)\n",
        "print(strings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEb2FfvEPK2h",
        "outputId": "14fe1733-8a60-40b9-bc47-93842f8a1f67"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[33901, 86, 343, 86, 220, 959]\n",
            "Akwirw ier\n"
          ]
        }
      ]
    }
  ]
}